Hive 编程指南

hive on EMR
弹性MapReduce 性价比比较高 对新工具新创意测试
先使用小实例 使用Ganglia监控性能
确保EC2实例 键对 安全组 和EMR工作流在同一个区域中
EMR AWS管理控制台 规模增大 使用其他方式进行搭建
EMR elastic-mapreduc CLI
EMR API 缺点可能不够新
Amazon Thrift端口号是改变的
EMR 管理者master实例组（namenode jobtracker）
核心实例组(datanode taskTracker)(集群停止数据丢失) 结点个数不能减少
任务实例组(task tracker) 可以增加和减少 降低成本又不会丢数据

s3n性能更好
部署hive-site.xml文件
安装hive --instal-hive --hive-versions
安装hive-site 指定文件脚本
elastice --brotstrapmapreduce 配置内存密集性任务的机器

EMR hive元数据的存储
1)使用JDBC连接元数据存储
2）使用初始化脚本 startup.q 或者使用.hiverc自动调用开机启动
3）在S3上进行Mysql的dump工作

EMR中的HDFS和S3
中间数据存储在HDFS中 需要持久化的数据再存储到S3中
数据在s3中的缺点 无法使用hadoop本地化数据处理优化 在处理前就将这些热数据导入到hdfs中 然后在进行处理
就可以在后续使用hadoop本地的处理优化

用户需要将所有初始化脚本 配置脚本 资源文件 UDF/Streaming 用到的JAR文件上传到S3上

S3上的日志
elatic-mapreduce下的creentdials.json配置
--log-uri
注意要频繁的清除日志 减少产生的存储成本

现买现卖
1）将中间结果存储到S3中
2）只把任务实例作为先买现卖结点 可以加快整个工作流
先买现卖任务可能导致太多次的map失败导致hadoop
可以通过修改mapred.reduce.max.attempts,mapred.map.max.attempts
修改任务的最多尝试次数
依赖太多的现买现卖实例导致无法推测执行或者任务失败
如果想访问EMR的9100 9101端口 通过ssh 或者同台sock

启动EMRhive对S3文件系统的优化
set hive.optimize.s3.query=true

alter table xxx recover partitions;

Tez有以下几个特色：
（1） 丰富的数据流接口；
（2） 扩展性良好的“Input-Processor-Output”运行模型；
（3） 简化数据部署（充分利用了YARN框架，Tez本身仅是一个客户端编程库，无需事先部署相关服务）
（4） 性能优于MapReduce
（5） 优化的资源管理（直接运行在资源管理系统YARN之上）
（6） 动态生成物理数据流

hive on tez，直接配置hive支持tez，其实是在yarn上面启动一个app,这个app永久运行,接受不同sql，除非退出hive cli此app才会结束
tez runing app在yarn上面和spark on yarn很类似，而且tez,spark底层原理也很相似！
在切换底层为mr引擎的时候也会重启app运行，但是tez那个app也没结束，等待mr app运行结束后,两个一起结束！

原本打算自己编译的，发现编译到tez-ui的时候总是报错，除非跳过不使用tez-ui；多次编译都是失败了，暂时先放一边了；直接使用官网已经编译好的包吧；

备注：Tez-ui是一个 Web界面可以看到Job的信息的执行时间，通过它可以更好、更直观的了解到程序慢在哪个位置；

hadoop -->    mapreduce     -->    sql,hql(hive)
(hdfs)      (特别的计算模型)        (不需要快速出结果)
限制：
1）不支持记录级别更新插入删除 由于mapreduce 时间长 hive不支持事务

2) 类似OLAP工具
   OLTP On-Line Transaction Processing
   这样做的最大优点是可以即时地处理输入的数据，及时地回答。也称为实时系统(Real time System)。
   衡量联机事务处理结果的一个重要指标是系统性能，具体体现为实时请求-响应时间(Response Time)，
   即用户在终端上输入数据之后，到计算机对这个请求给出答复所需要的时间。OLTP是由前台、应用、数据库共同完成的，
   处理快慢以及处理程度取决于数据库引擎、服务器、应用引擎。OLTP 数据库旨在使事务应用程序仅写入所需的数据，以便尽快处理单个事务。
   Online Analytical Processing hive 不满足联机部分
   hadoop+hbase emr/ec2+dynamoDB

Map + Reducer
map 集合的一种形式到另一种形式
reudcer 键-值对 输入和输出的键值是不同
hadoop 备份3份 64M或者倍数
减少写入读取次数
input -> mappers -> shuffle(重新分发)/combine(小范围sort)/sort -> reducers -> output

hive cli hwi(网页界面) jdbc odbc thrift
hive -> job执行计划 -> 执行mapper/reducer模块 hive网关机 -> NameNode
pig 数据流 步进式的数据流更加直观
hbase 行级别的数据更新 快速查询 行级事务
Hbase 只查询部分列会很快
Hbase 内存缓存技术 + hdfs
本地文件的内存患处技术 数据更新操作日志
没有使用mapreduce的工具
spark（shark） storm kafka
hadoop
单点 伪分布式 分布式
hive内部是什么
$HIVE_HOME/lib
Thrift 提供了了远程访问其他进程
hive客户端 ---> metastoreservice
使用Derby数据库是 用户不可以并发两个hiveCLI实例
derby --> metastore_db
默认路径是user/hive/warehouse hive.metastore.local hive类路径要有jdbc
hive --auxpath 允许用户指定以猫号分割的附属的jar包
--config 指定一个新的配置文件的目录
set 命令 显示修改变量值
set, set -v所有变量 hadoop hdfs mapreduce 的属性
set 还可以给变量赋新的值
hive --define 定义变量
hive --define foo=bar --hivevar --define的标记是相同的
set hivevar:foo=bar;
create table toss1(i int, ${hivevar:foo} string);
system: 命名空间 Java可读可写 对env：只能读
hivevar rw 用户自定义变量
hiveconf rw Hive相关的配置属性
system rw  Java定义的配置属性
env    r    shell环境 bash环境的变量
hive -e 一次执行命令
hive -s 静默模式 去掉 ok 和 Time taken等行
hive -f 执行指定文件中一个多个查询语句 *.q *.hql
hive shell中可使用source来执行一个脚本文件
.hiverc 文件中有内容在cli启动前自动执行文件命令
历史记录在~/.hivehistory
hiveshell中 !简单的shell命令;
hiveshell中 dfs -ls / ;更高效的dfs的命令
set hive.cli.print.header=true cli 打印出字段名称